{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb4c321",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.evaluation.metrics import JailbreakEvaluator, print_evaluation_summary\n",
    "from src.data.dataset_loader import DatasetLoader\n",
    "from configs.models.model_config import MODELS, RECOMMENDED_MODELS\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd23950",
   "metadata": {},
   "source": [
    "## 1. Load Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaba6503",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DatasetLoader()\n",
    "\n",
    "# Load test prompts\n",
    "test_data = loader.load_jsonl('../data/processed/advbench/test.jsonl')\n",
    "test_prompts = [item['prompt'] for item in test_data]\n",
    "\n",
    "print(f\"Loaded {len(test_prompts)} test prompts\")\n",
    "print(f\"\\nExample: {test_prompts[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cb3975",
   "metadata": {},
   "source": [
    "## 2. Simulate Baseline Responses\n",
    "\n",
    "For demonstration, we'll simulate different response types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea60360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate different models with varying safety levels\n",
    "import random\n",
    "\n",
    "def simulate_model_responses(prompts, refusal_prob=0.5):\n",
    "    \"\"\"Simulate model responses with given refusal probability.\"\"\"\n",
    "    safe_templates = [\n",
    "        \"I cannot help with that request as it could be harmful.\",\n",
    "        \"I'm not able to assist with that.\",\n",
    "        \"I must decline that request.\"\n",
    "    ]\n",
    "    \n",
    "    unsafe_templates = [\n",
    "        \"Sure, here's what you need to know...\",\n",
    "        \"I can help you with that. Here are the steps...\",\n",
    "        \"Let me guide you through this process...\"\n",
    "    ]\n",
    "    \n",
    "    responses = []\n",
    "    for prompt in prompts:\n",
    "        if random.random() < refusal_prob:\n",
    "            responses.append(random.choice(safe_templates))\n",
    "        else:\n",
    "            responses.append(random.choice(unsafe_templates))\n",
    "    \n",
    "    return responses\n",
    "\n",
    "# Simulate 3 models with different safety levels\n",
    "models_simulated = {\n",
    "    'Unsafe Model': simulate_model_responses(test_prompts[:50], refusal_prob=0.2),\n",
    "    'Baseline Model': simulate_model_responses(test_prompts[:50], refusal_prob=0.5),\n",
    "    'Safe Model': simulate_model_responses(test_prompts[:50], refusal_prob=0.9)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f32fcb",
   "metadata": {},
   "source": [
    "## 3. Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48775ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = JailbreakEvaluator()\n",
    "\n",
    "# Evaluate each model\n",
    "results = {}\n",
    "for model_name, responses in models_simulated.items():\n",
    "    result = evaluator.evaluate(\n",
    "        prompts=test_prompts[:50],\n",
    "        responses=responses\n",
    "    )\n",
    "    results[model_name] = result\n",
    "    print_evaluation_summary(result, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7c5d5f",
   "metadata": {},
   "source": [
    "## 4. Compare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af46fdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract metrics for comparison\n",
    "comparison_data = []\n",
    "for model_name, result in results.items():\n",
    "    comparison_data.append({\n",
    "        'Model': model_name,\n",
    "        'Refusal Rate': result['overall']['refusal_rate'],\n",
    "        'ASR': result['overall']['attack_success_rate'],\n",
    "        'Safety Score': result['overall']['safety_score']\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210bb39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Refusal Rate\n",
    "axes[0].bar(comparison_df['Model'], comparison_df['Refusal Rate'])\n",
    "axes[0].set_ylabel('Refusal Rate')\n",
    "axes[0].set_title('Model Refusal Rates')\n",
    "axes[0].set_ylim(0, 1)\n",
    "plt.setp(axes[0].xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "\n",
    "# Attack Success Rate\n",
    "axes[1].bar(comparison_df['Model'], comparison_df['ASR'], color='orange')\n",
    "axes[1].set_ylabel('Attack Success Rate')\n",
    "axes[1].set_title('Model Attack Success Rates')\n",
    "axes[1].set_ylim(0, 1)\n",
    "plt.setp(axes[1].xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77653da0",
   "metadata": {},
   "source": [
    "## 5. Response Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f72278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze response patterns\n",
    "for model_name, result in results.items():\n",
    "    print(f\"\\n{model_name} - Sample Responses:\\n\")\n",
    "    \n",
    "    # Show examples of refusals and non-refusals\n",
    "    examples = result['examples'][:5]\n",
    "    \n",
    "    for i, ex in enumerate(examples, 1):\n",
    "        status = \"ðŸŸ¢ REFUSED\" if ex['refused'] else \"ðŸ”´ COMPLIED\"\n",
    "        print(f\"{i}. {status}\")\n",
    "        print(f\"   Prompt: {ex['prompt'][:60]}...\")\n",
    "        print(f\"   Response: {ex['response']}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53735ce",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. Train models with DPO: `python src/training/train_dpo.py`\n",
    "2. Compare before/after DPO in next notebook\n",
    "3. Run real evaluations with actual models"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
